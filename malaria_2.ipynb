{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEXTM-uqClXJ",
        "outputId": "5f237d08-0779-416b-c355-d6dc66ad4dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnvgwEA272q1",
        "outputId": "fb297472-cafc-424a-e1ca-113740182a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import splitfolders"
      ],
      "metadata": {
        "id": "e2FZDzErC06n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_folder=\"/gdrive/MyDrive/malaria_para_thesis/cell_images_input\"\n",
        "# output=\"/gdrive/MyDrive/malaria_para_thesis/processed_dataset\"\n",
        "#splitfolders.ratio(input_folder,output,seed=42,ratio=(.8, 0.2,.0))"
      ],
      "metadata": {
        "id": "QUZE6lLi79lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Set the `numpy` pseudo-random generator at a fixed value\n",
        "#This helps with repeatable results everytime you run the code.\n",
        "np.random.seed(1000)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import keras\n",
        "\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow' # Added to set the backend as Tensorflow\n",
        "#We can also set it to Theano if we want.\n"
      ],
      "metadata": {
        "id": "-rsYK6HjAHnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D,MaxPool2D, Dense, Flatten,BatchNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input,decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "metadata": {
        "id": "r2w9iiphATvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_ = 64\n",
        "img_height,img_width = (64,64)\n",
        "\n",
        "\n",
        "train_data_dir=r\"/gdrive/MyDrive/malaria_para_thesis/processed_dataset/train\"\n",
        "valid_data_dir=r\"/gdrive/MyDrive/malaria_para_thesis/processed_dataset/val\"\n",
        "#test_data_dir=r\"flowers_dataset/processed_dataset/test\""
      ],
      "metadata": {
        "id": "9RO4zSx1Afrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    # shear_range=0.2,\n",
        "    #zoom_range=0.3,\n",
        "    #horizontal_flip=True,\n",
        "    #width_shift_range=0.2,\n",
        "   # height_shift_range=0.2,\n",
        "    #rotation_range=30\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=batch_size_)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=batch_size_)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU0uFMykAv2b",
        "outputId": "77989f0b-3835-47d2-f7e0-3148daec978c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22077 images belonging to 2 classes.\n",
            "Found 5519 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW0oO1-xURsy",
        "outputId": "d9d8144f-adc9-484b-ec91-d5cd5217b145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=val_generator.next()\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfUeg2aGA1JZ",
        "outputId": "ee5839ae-ba88-442c-a2cb-e89d9f30641e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 256, 256, 3), (32, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_ = 1e-3\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "SIZE = 64"
      ],
      "metadata": {
        "id": "1uMKuFUZF_N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.applications.ResNet50(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(256, 256,3),\n",
        "#     pooling=None,\n",
        "#     classes=2,\n",
        "# )\n",
        "# # densenet 121, 169, 201\n",
        "# x = GlobalAveragePooling2D()(model.output)\n",
        "# x = Dense(1024, 'relu')(x)\n",
        "# x = Dense(256, 'relu')(x)\n",
        "# x = Dense(2, 'softmax')(x)\n",
        "\n",
        "# model = Model(model.input, x)\n",
        "# model.summary()\n",
        "\n",
        "# model.compile(tf.keras.optimizers.Adam(learning_rate=lr_),\n",
        "#                   'categorical_crossentropy',\n",
        "#                   ['accuracy'])\n",
        "\n",
        "\n",
        "#Apply CNN\n",
        "# ### Build the model\n",
        "\n",
        "#############################################################\n",
        "###2 conv and pool layers. with some normalization and drops in between.\n",
        "\n",
        "INPUT_SHAPE = (SIZE, SIZE, 3)   #change to (SIZE, SIZE, 3)\n",
        "inp = keras.layers.Input(shape=INPUT_SHAPE)\n",
        "\n",
        "conv1 = keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                               activation='relu', padding='same')(inp)\n",
        "pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "norm1 = keras.layers.BatchNormalization(axis = -1)(pool1)\n",
        "drop1 = keras.layers.Dropout(rate=0.2)(norm1)\n",
        "conv2 = keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                               activation='relu', padding='same')(drop1)\n",
        "pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "norm2 = keras.layers.BatchNormalization(axis = -1)(pool2)\n",
        "drop2 = keras.layers.Dropout(rate=0.2)(norm2)\n",
        "\n",
        "flat = keras.layers.Flatten()(drop2)  #Flatten the matrix to get it ready for dense.\n",
        "\n",
        "hidden1 = keras.layers.Dense(512, activation='relu')(flat)\n",
        "norm3 = keras.layers.BatchNormalization(axis = -1)(hidden1)\n",
        "drop3 = keras.layers.Dropout(rate=0.2)(norm3)\n",
        "hidden2 = keras.layers.Dense(256, activation='relu')(drop3)\n",
        "norm4 = keras.layers.BatchNormalization(axis = -1)(hidden2)\n",
        "drop4 = keras.layers.Dropout(rate=0.2)(norm4)\n",
        "\n",
        "out = keras.layers.Dense(2, activation='sigmoid')(drop4)   #units=1 gives error\n",
        "\n",
        "model = keras.Model(inputs=inp, outputs=out)\n",
        "model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',   #Check between binary_crossentropy and categorical_crossentropy\n",
        "                metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjKUj-2oBBes",
        "outputId": "329b1de8-4358-4245-8f0f-1790e6fd651c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               4194816   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,340,130\n",
            "Trainable params: 4,338,466\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "KCQRGxvaBH86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annelear = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10, verbose=1,\n",
        "                             mode='auto', min_lr=1e-8)\n",
        "\n",
        "path_to_save = 'gdrive/MyDrive/malaria_para_thesis/resnet_50_epo20.h5'\n",
        "\n",
        "#'/content/PBF0_d212.h5'\n",
        "#'/content/drive/MyDrive/Terms/Thesis/WCE DATA/Trainings/d169_fold'+str(fold)+'.h5'   ---> Random Fold\n",
        "\n",
        "save_W = ModelCheckpoint(path_to_save,\n",
        "                          monitor='val_accuracy',mode ='max',verbose=1,\n",
        "                          save_best_only=True, save_weights_only=True)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                        batch_size=batch_size_,\n",
        "                        epochs=10, verbose=1,\n",
        "                        validation_data=(val_generator),\n",
        "                        # shuffle=True,\n",
        "                        callbacks=[annelear, save_W],)"
      ],
      "metadata": {
        "id": "BOcWlUEKBN9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Accuracy calculation\n",
        "#\n",
        "# I'll now calculate the accuracy on the test data.\n",
        "\n",
        "#print(\"Test_Accuracy: {:.2f}%\".format(model.evaluate(np.array(X_test), np.array(y_test))[1]*100))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "max_epoch = len(history.history['accuracy'])+1\n",
        "epoch_list = list(range(1,max_epoch))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "SZOFgA6cBSPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPhzPRvNMaq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_acc = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)[1]\n",
        "#print(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))\n",
        "test_loss,test_acc=model.evaluate(val_generator,verbose=1)\n",
        "print('\\nTest_accuracy',test_acc)"
      ],
      "metadata": {
        "id": "Vq6AVkDXCK19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "#model.save('/gdrive/MyDrive/malaria_para_thesis/try1_30epoch.h5')"
      ],
      "metadata": {
        "id": "Q2GbW-zfCPzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model=tf.keras.models.load_model(\"/gdrive/MyDrive/malaria_para_thesis/weights-improvement.h5\")\n",
        "# score = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
        "# print('Test accuracy:', score[1])                                                                        for comment ctrl+/\n",
        "\n",
        "test_loss,test_acc=model.evaluate(val_generator,verbose=1)\n",
        "print('\\nTest_accuracy',test_acc)"
      ],
      "metadata": {
        "id": "qKHVIc3BCXKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_ = '/gdrive/MyDrive/flower/resnet_50_epo10.h5'\n",
        "model.load_weights(weight_)"
      ],
      "metadata": {
        "id": "omv8R_zj-oRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tqdm import tqdm"
      ],
      "metadata": {
        "id": "oJFit0TPTWEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator.reset()\n",
        "# X_train, y_train = next(train_generator)\n",
        "# for i in tqdm(range(int(len(train_generator)/batch_size_)-1)): #1st batch is already fetched before the for loop.\n",
        "#   img, label = next(train_generator)\n",
        "#   X_train = np.append(X_train, img, axis=0 )\n",
        "#   y_train = np.append(y_train, label, axis=0)\n",
        "# print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV6l_3IGNfd5",
        "outputId": "ff2fd52b-8b02-46fa-a3a3-1ab0940dea86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:17<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(672, 256, 256, 3) (672, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input,decode_predictions\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from seaborn import heatmap\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "m3uZDfJNCZ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #models=tf.keras.models.load_model(\"dataset_2\\ResNet50_xray224.h5\")\n",
        "# preds = np.argmax(model.predict(np.array(X_test)), axis=1)\n",
        "# acc = accuracy_score(y_testt, np.round(preds))*100\n",
        "# cm = confusion_matrix(y_testt, np.round(preds))\n",
        "# cm_norm = confusion_matrix(y_testt, np.round(preds), normalize='true')\n",
        "# #tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# print('CONFUSION MATRIX ------------------')\n",
        "\n",
        "# ax = heatmap(cm, cmap='Blues', linecolor='lightblue',linewidths=.5,annot=True,annot_kws={'size': 12,\"weight\": \"bold\"}, xticklabels=['parasitized', 'uninfected'], yticklabels= ['parasitized', 'uninfected'], square=True, fmt='d')\n",
        "\n",
        "# ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)\n",
        "# ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 12,rotation=0)\n",
        "\n",
        "# # plt.savefig(confusion_matrix_save_path+model_name+'.png',dpi=500)\n",
        "# plt.show()\n",
        "\n",
        "# ax = heatmap(cm_norm, cmap='Blues', annot=True,linecolor='lightblue',linewidths=.5,annot_kws={'size': 12,\"weight\": \"bold\"}, xticklabels=['parasitized', 'uninfected'], yticklabels=['parasitized', 'uninfected'], square=True, fmt='.2f')\n",
        "\n",
        "# ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)\n",
        "# ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 12,rotation=0)\n",
        "\n",
        "# # plt.savefig(confusion_matrix_save_path+model_name+'_normalized.png',dpi=500)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "NXlI-LJ3OXcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(classification_report(y_testt, preds))"
      ],
      "metadata": {
        "id": "sXv2P237CsQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "model=tf.keras.models.load_model(\"ResNet50_flower.h5\")\n",
        "filenames=test_generator.filenames\n",
        "nb_samples=len(val_generator)\n",
        "y_prob=[]\n",
        "y_act=[]\n",
        "val_generator.reset()\n",
        "\n",
        "for _ in range(nb_samples):\n",
        "    X_test,Y_test=val_generator.next()\n",
        "    y_prob.append(model.predict(X_test))\n",
        "    y_act.append(Y_test)\n",
        "\n",
        "predicted_class=[list(train_generator.class_indices.keys())[i.argmax()]for i in y_prob]\n",
        "actual_class=[list(train_generator.class_indices.keys())[i.argmax()]for i in y_act]\n",
        "out_df=pd.DataFrame(np.vstack([predicted_class,actual_class]).T,columns=['predicted_class','actual_class'])\n",
        "\n"
      ],
      "metadata": {
        "id": "s0J23btECif2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix=pd.crosstab(out_df['actual_class'],out_df['predicted_class'],rownames=['Actual'],colnames=['Predicted'])\n",
        "sn.heatmap(confusion_matrix,cmap='Blues',annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "uSGommFCPH4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}